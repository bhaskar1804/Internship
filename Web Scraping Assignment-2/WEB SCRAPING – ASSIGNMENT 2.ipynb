{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "e69f93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import time\n",
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "458ed762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business and Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CAREERDOST ENTERPRISE</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>We are open to consider Freshers either of 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAS Analyst / data Analyst / Business analyst ...</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Leading US MNC into analytics</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Tier 1 &amp; 2 candidates will be on preference At...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bioclinica</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Bachelor s degree in an Engineering, Science, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell</td>\n",
       "      <td>10-12 Yrs</td>\n",
       "      <td>This job profile contains generic information ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst, Data &amp; Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ReSource Pro Operational Solutions Pvt Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>4 years minimum experience in data analysis wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring - Zonal Data Analyst (Off Role) - Opera...</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Rupeek</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Minimum graduate from a recognized universityC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>LatentView</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>manage the Client Relationship by interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr Domain Expert -Data Analysts</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>0-10 Yrs</td>\n",
       "      <td>Must be able to manage a team of 5 and guide t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst Sr</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Epsilon</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "      <td>Job Summary The Senior Analyst supports Genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cerner</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "      <td>At least 5 years Additional work experience di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                          Business and Data Analyst   \n",
       "1  SAS Analyst / data Analyst / Business analyst ...   \n",
       "2                                     Data Analyst I   \n",
       "3                                Senior Data Analyst   \n",
       "4              Senior Data Analyst, Data & Analytics   \n",
       "5  Hiring - Zonal Data Analyst (Off Role) - Opera...   \n",
       "6                                Senior Data Analyst   \n",
       "7                    Sr Domain Expert -Data Analysts   \n",
       "8                                    Data Analyst Sr   \n",
       "9                                    Data Analyst II   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                     New Delhi, Bangalore/Bengaluru   \n",
       "6                       Chennai, Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                       Company Experience  \\\n",
       "0                        CAREERDOST ENTERPRISE    0-5 Yrs   \n",
       "1                Leading US MNC into analytics    2-7 Yrs   \n",
       "2                                   Bioclinica    0-3 Yrs   \n",
       "3                                        Shell  10-12 Yrs   \n",
       "4  ReSource Pro Operational Solutions Pvt Ltd.    3-5 Yrs   \n",
       "5                                       Rupeek    2-7 Yrs   \n",
       "6                                   LatentView    3-6 Yrs   \n",
       "7                                      Siemens   0-10 Yrs   \n",
       "8                                      Epsilon    5-7 Yrs   \n",
       "9                                       Cerner   6-10 Yrs   \n",
       "\n",
       "                                     Job_Description  \n",
       "0  We are open to consider Freshers either of 202...  \n",
       "1  Tier 1 & 2 candidates will be on preference At...  \n",
       "2  Bachelor s degree in an Engineering, Science, ...  \n",
       "3  This job profile contains generic information ...  \n",
       "4  4 years minimum experience in data analysis wi...  \n",
       "5  Minimum graduate from a recognized universityC...  \n",
       "6  manage the Client Relationship by interacting ...  \n",
       "7  Must be able to manage a team of 5 and guide t...  \n",
       "8  Job Summary The Senior Analyst supports Genera...  \n",
       "9  At least 5 years Additional work experience di...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.'''\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "driver.get('https://www.naukri.com/')\n",
    "driver.maximize_window()\n",
    "designation=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input')\n",
    "designation.send_keys('Data Analyst')\n",
    "location=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "location.send_keys('Bangalore')\n",
    "search=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search.click()\n",
    "time.sleep(2)\n",
    "\n",
    "Job_title=[]\n",
    "Job_location=[]\n",
    "Company_name=[]\n",
    "Experience=[]\n",
    "Job_desc=[]\n",
    "\n",
    "t=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "t2=t[0:10]\n",
    "\n",
    "for i in t2:\n",
    "    Job_title.append(i.text)\n",
    "\n",
    "l=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "l2=l[0:10]\n",
    "\n",
    "for i in l2:\n",
    "    Job_location.append(i.text)\n",
    "\n",
    "c=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "c2=c[0:10]\n",
    "\n",
    "for i in c2:\n",
    "    Company_name.append(i.text)\n",
    "    \n",
    "e=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "e2=e[0:10]\n",
    "\n",
    "for i in e2:\n",
    "    Experience.append(i.text)\n",
    "    \n",
    "jd=driver.find_elements_by_xpath(\"//article[@class='jobTuple bgWhite br4 mb-8']/div[2]\")\n",
    "jd2=jd[0:10]\n",
    "\n",
    "for i in jd2:\n",
    "    Job_desc.append(i.text)\n",
    "    \n",
    "Job_Details=pd.DataFrame({'Title':Job_title,'Location':Job_location,'Company':Company_name,'Experience':Experience,'Job_Description':Job_desc})\n",
    "Job_Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da08c27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist (IN4)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Master s/ PhD or any other graduation degree w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Your Opportunity As a Senior Data Scientist fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Ericsson Global Services</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "      <td>To be successful in the role you must have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Truecaller</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>As a Senior Data Scientist you will be respons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Staff Engineer Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infineon Technologies Pvt Ltd</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Bachelors / Master Degree in Computer Science,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>As a Data Scientist at IBM, you will help tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - IN3</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>7-11 Yrs</td>\n",
       "      <td>Master s/ PhD or any other graduation degree w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science - Data Scientist</td>\n",
       "      <td>Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Machine learning experience of 1-3 years of im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FTE - Regional BI - Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Knowledge of Big Data AWS technologies (S3, Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>IBM Maximo Certified Deployment Consultant (V6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Title                   Location  \\\n",
       "0              Senior Data Scientist (IN4)        Bangalore/Bengaluru   \n",
       "1                    Senior Data Scientist        Bangalore/Bengaluru   \n",
       "2                    Senior Data Scientist        Bangalore/Bengaluru   \n",
       "3                    Senior Data Scientist        Bangalore/Bengaluru   \n",
       "4            Staff Engineer Data Scientist        Bangalore/Bengaluru   \n",
       "5       Data Scientist: Advanced Analytics        Bangalore/Bengaluru   \n",
       "6                     Data Scientist - IN3        Bangalore/Bengaluru   \n",
       "7            Data Science - Data Scientist  Pune, Bangalore/Bengaluru   \n",
       "8       FTE - Regional BI - Data Scientist        Bangalore/Bengaluru   \n",
       "9  Data Scientist: Artificial Intelligence        Bangalore/Bengaluru   \n",
       "\n",
       "                         Company Experience  \\\n",
       "0                        Walmart    5-9 Yrs   \n",
       "1                        Walmart    5-9 Yrs   \n",
       "2       Ericsson Global Services  10-15 Yrs   \n",
       "3                     Truecaller    2-5 Yrs   \n",
       "4  Infineon Technologies Pvt Ltd    1-3 Yrs   \n",
       "5                            IBM    2-5 Yrs   \n",
       "6                        Walmart   7-11 Yrs   \n",
       "7                          Paytm    1-3 Yrs   \n",
       "8             Schneider Electric    3-5 Yrs   \n",
       "9                            IBM    3-7 Yrs   \n",
       "\n",
       "                                     Job_Description  \n",
       "0  Master s/ PhD or any other graduation degree w...  \n",
       "1  Your Opportunity As a Senior Data Scientist fo...  \n",
       "2         To be successful in the role you must have  \n",
       "3  As a Senior Data Scientist you will be respons...  \n",
       "4  Bachelors / Master Degree in Computer Science,...  \n",
       "5  As a Data Scientist at IBM, you will help tran...  \n",
       "6  Master s/ PhD or any other graduation degree w...  \n",
       "7  Machine learning experience of 1-3 years of im...  \n",
       "8  Knowledge of Big Data AWS technologies (S3, Re...  \n",
       "9  IBM Maximo Certified Deployment Consultant (V6...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data'''\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "designation=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input')\n",
    "designation.send_keys('Data Scientist')\n",
    "location=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "location.send_keys('Bangalore')\n",
    "search=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search.click()\n",
    "time.sleep(2)\n",
    "\n",
    "Job_title1=[]\n",
    "Job_location1=[]\n",
    "Company_name1=[]\n",
    "Experience1=[]\n",
    "Job_desc1=[]\n",
    "\n",
    "t1=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "t21=t1[0:10]\n",
    "\n",
    "for i in t21:\n",
    "    Job_title1.append(i.text)\n",
    "\n",
    "l1=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "l21=l1[0:10]\n",
    "\n",
    "for i in l21:\n",
    "    Job_location1.append(i.text)\n",
    "\n",
    "c1=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "c21=c1[0:10]\n",
    "\n",
    "for i in c21:\n",
    "    Company_name1.append(i.text)\n",
    "    \n",
    "e1=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "e21=e1[0:10]\n",
    "\n",
    "for i in e21:\n",
    "    Experience1.append(i.text)\n",
    "    \n",
    "jd1=driver.find_elements_by_xpath(\"//article[@class='jobTuple bgWhite br4 mb-8']/div[2]\")\n",
    "jd21=jd1[0:10]\n",
    "\n",
    "for i in jd21:\n",
    "    Job_desc1.append(i.text)\n",
    "    \n",
    "Job_Details_DS=pd.DataFrame({'Title':Job_title1,'Location':Job_location1,'Company':Company_name1,'Experience':Experience1,'Job_Description':Job_desc1})\n",
    "Job_Details_DS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaa25014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Primary Responsibilities:Work closely with a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist (freelance)</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "      <td>2Coms</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Experience using web services: Redshift, S3, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Senior Data Scientist-Noida</td>\n",
       "      <td>Noida, Greater Noida, Delhi / NCR</td>\n",
       "      <td>Lumiq.ai</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Role: Senior Data Scientist Experience: 2+ Yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Opening For Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Care Health Insurance</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Experience in data mining and development of p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist/ Machine Learning, 2022 Passout...</td>\n",
       "      <td>Hyderabad/Secunderabad, Ahmedabad, Chennai, Ba...</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "      <td>2022 graduate can also apply Freshers are pref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon, Bengaluru</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Some of the problem areas are Insights across ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Recent PhD or Master s Degree in computer scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Urgent Requirement || Data Scientist || Noida</td>\n",
       "      <td>Noida, Delhi / NCR</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Education- Bachelors Degree (Computer Science)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AM Data Scientist - Goods &amp; Service Tax Networ...</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>NISG (National Institute for Smart Government)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Tech/ BE / MCA / MBA-IT Knowledge in software ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>About CompanyMIND is an IT services company, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                           Associate Data Scientist   \n",
       "1                         Data Scientist (freelance)   \n",
       "2             Hiring For Senior Data Scientist-Noida   \n",
       "3                         Opening For Data Scientist   \n",
       "4  Data Scientist/ Machine Learning, 2022 Passout...   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7      Urgent Requirement || Data Scientist || Noida   \n",
       "8  AM Data Scientist - Goods & Service Tax Networ...   \n",
       "9                     Data Scientist - MIND Infotech   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                   Gurgaon/Gurugram   \n",
       "1                                   New Delhi, Delhi   \n",
       "2                  Noida, Greater Noida, Delhi / NCR   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4  Hyderabad/Secunderabad, Ahmedabad, Chennai, Ba...   \n",
       "5                                 Gurgaon, Bengaluru   \n",
       "6                                          New Delhi   \n",
       "7                                 Noida, Delhi / NCR   \n",
       "8                                        Delhi / NCR   \n",
       "9                                              Noida   \n",
       "\n",
       "                                          Company Experience  \\\n",
       "0                                           Optum    1-5 Yrs   \n",
       "1                                           2Coms    2-7 Yrs   \n",
       "2                                        Lumiq.ai    2-6 Yrs   \n",
       "3                           Care Health Insurance    1-5 Yrs   \n",
       "4                   Creative Hands HR Consultancy    0-4 Yrs   \n",
       "5                                       BlackBuck    3-7 Yrs   \n",
       "6                         Boston Consulting Group    2-5 Yrs   \n",
       "7                                HCL Technologies    3-8 Yrs   \n",
       "8  NISG (National Institute for Smart Government)    3-8 Yrs   \n",
       "9        MOTHERSONSUMI INFOTECH & DESIGNS LIMITED    4-8 Yrs   \n",
       "\n",
       "                                     Job_Description  \n",
       "0  Primary Responsibilities:Work closely with a l...  \n",
       "1  Experience using web services: Redshift, S3, S...  \n",
       "2  Role: Senior Data Scientist Experience: 2+ Yea...  \n",
       "3  Experience in data mining and development of p...  \n",
       "4  2022 graduate can also apply Freshers are pref...  \n",
       "5  Some of the problem areas are Insights across ...  \n",
       "6  Recent PhD or Master s Degree in computer scie...  \n",
       "7  Education- Bachelors Degree (Computer Science)...  \n",
       "8  Tech/ BE / MCA / MBA-IT Knowledge in software ...  \n",
       "9  About CompanyMIND is an IT services company, i...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q3: In this question you have to scrape data using the filters available on the webpage as shown below: \n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.'''\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "driver.get('https://www.naukri.com/')\n",
    "driver.maximize_window()\n",
    "\n",
    "designation=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input')\n",
    "designation.send_keys('Data Scientist')\n",
    "search=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search.click()\n",
    "time.sleep(2)\n",
    "sub_location=driver.find_element_by_xpath(\"//span[@title='Delhi / NCR']\")\n",
    "sub_location.click()\n",
    "time.sleep(3)\n",
    "salary_filter=driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\").click()\n",
    "time.sleep(3)\n",
    "Job_title1=[]\n",
    "Job_location1=[]\n",
    "Company_name1=[]\n",
    "Experience1=[]\n",
    "Job_desc1=[]\n",
    "\n",
    "\n",
    "t1=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "t21=t1[0:10]\n",
    "\n",
    "for i in t21:\n",
    "    Job_title1.append(i.text)\n",
    "\n",
    "l1=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "l21=l1[0:10]\n",
    "\n",
    "for i in l21:\n",
    "    Job_location1.append(i.text)\n",
    "\n",
    "c1=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "c21=c1[0:10]\n",
    "\n",
    "for i in c21:\n",
    "    Company_name1.append(i.text)\n",
    "    \n",
    "e1=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "e21=e1[0:10]\n",
    "\n",
    "for i in e21:\n",
    "    Experience1.append(i.text)\n",
    "    \n",
    "jd1=driver.find_elements_by_xpath(\"//article[@class='jobTuple bgWhite br4 mb-8']/div[2]\")\n",
    "jd21=jd1[0:10]\n",
    "\n",
    "for i in jd21:\n",
    "    Job_desc1.append(i.text)\n",
    "    \n",
    "Job_Details_Delhi=pd.DataFrame({'Title':Job_title1,'Location':Job_location1,'Company':Company_name1,'Experience':Experience1,'Job_Description':Job_desc1})\n",
    "Job_Details_Delhi\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc958163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>Polarized, UV Protection, Riding Glasses Wayfa...</td>\n",
       "      <td>₹375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (53)</td>\n",
       "      <td>₹387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Poloport</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Mirrored Round Sunglasses (Free...</td>\n",
       "      <td>₹899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description Price\n",
       "0        Rich Club  Polarized, UV Protection, Riding Glasses Wayfa...  ₹375\n",
       "1     Silver Kartz           UV Protection Clubmaster Sunglasses (53)  ₹387\n",
       "2        Elligator                UV Protection Round Sunglasses (54)  ₹355\n",
       "3         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹647\n",
       "4         Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹639\n",
       "..             ...                                                ...   ...\n",
       "95          GANSTA  UV Protection, Gradient Retro Square Sunglasse...  ₹221\n",
       "96       Rich Club      UV Protection Wayfarer Sunglasses (Free Size)  ₹253\n",
       "97  ROZZETTA CRAFT  Polarized, UV Protection Retro Square Sunglass...  ₹349\n",
       "98        Poloport  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹249\n",
       "99       ROYAL SON  UV Protection, Mirrored Round Sunglasses (Free...  ₹899\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands andmore” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the\n",
    "required data as usual.\n",
    "ASSIGNMENT 2\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom ofthe page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses'''\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/div/div/button\").click()\n",
    "search=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search.send_keys('sunglass')\n",
    "SR=driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "SR.click()\n",
    "time.sleep(3)\n",
    "\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "\n",
    "\n",
    "pr=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "pr\n",
    "\n",
    "for i in pr:\n",
    "    \n",
    "    product_desc.append(i.text)   \n",
    "\n",
    "br=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "\n",
    "for i in br:\n",
    "    \n",
    "    brand.append(i.text)\n",
    "    \n",
    "rt=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "\n",
    "for i in rt:\n",
    "    \n",
    "    price.append(i.text)\n",
    "    \n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span\").click()\n",
    "time.sleep(3)\n",
    "\n",
    "pr=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "pr\n",
    "\n",
    "for i in pr:\n",
    "    \n",
    "    product_desc.append(i.text)   \n",
    "\n",
    "br=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "\n",
    "for i in br:\n",
    "    \n",
    "    brand.append(i.text)\n",
    "    \n",
    "rt=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "\n",
    "for i in rt:\n",
    "    \n",
    "    price.append(i.text)\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span\").click()\n",
    "time.sleep(3)\n",
    "\n",
    "pr=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "pr\n",
    "\n",
    "for i in pr:\n",
    "    \n",
    "    product_desc.append(i.text)   \n",
    "\n",
    "br=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "\n",
    "for i in br:\n",
    "    \n",
    "    brand.append(i.text)\n",
    "    \n",
    "rt=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "\n",
    "for i in rt:\n",
    "    \n",
    "    price.append(i.text)\n",
    "    \n",
    "Sunglasses=pd.DataFrame({'Brand': brand[0:100],'Description':product_desc[0:100],'Price':price[0:100]})\n",
    "Sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "e158e147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>5</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>I'm switching this phone to oppo reno 10x zoom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Simply Awesome\\n\\nI have upgraded from iPhone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Damn this phone is a blast . Upgraded from and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>4</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Worth the money’ starting first from its perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>I dreamt about this day from a long time.... G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings                Review  \\\n",
       "0        5             Brilliant   \n",
       "1        5        Simply awesome   \n",
       "2        5   Best in the market!   \n",
       "3        5      Perfect product!   \n",
       "4        5             Fabulous!   \n",
       "..     ...                   ...   \n",
       "85       5  Good quality product   \n",
       "86       5              Terrific   \n",
       "87       5   Best in the market!   \n",
       "88       4      Perfect product!   \n",
       "89       5               Awesome   \n",
       "\n",
       "                                       Review_Summary  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "85  I'm switching this phone to oppo reno 10x zoom...  \n",
       "86  Simply Awesome\\n\\nI have upgraded from iPhone ...  \n",
       "87  Damn this phone is a blast . Upgraded from and...  \n",
       "88  Worth the money’ starting first from its perfo...  \n",
       "89  I dreamt about this day from a long time.... G...  \n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. \n",
    "    \n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually'''\n",
    "    \n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZE3ENS&marketplace=FLIPKART&q=iphone+11&store=tyy%2F4io&srno=s_1_3&otracker=AS_Query_OrganicAutoSuggest_3_6_na_na_na&otracker1=AS_Query_OrganicAutoSuggest_3_6_na_na_na&fm=organic&iid=27c55a4e-3bff-45b6-b2e5-6fdfaedd3618.MOBFWQ6BXGJCEYNY.SEARCH&ppt=hp&ppn=homepage&ssid=uiq6ijmksg0000001651482370002&qH=f6cdfdaa9f3c23f3')\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[6]/div/a/div/span\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "ratings=[]\n",
    "review=[]\n",
    "summary=[]\n",
    "\n",
    "for i in range(2):\n",
    "    rt=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\") \n",
    "\n",
    "    for r in rt:\n",
    "        ratings.append(r.text)\n",
    "\n",
    "    \n",
    "    rv=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "\n",
    "    for s in rv:\n",
    "        review.append(s.text)\n",
    "    \n",
    "    su=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "\n",
    "    for t in su:\n",
    "        summary.append(t.text)\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    nxt=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]\")\n",
    "    time.sleep(2)\n",
    "    nxt.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "time.sleep(3)    \n",
    "    \n",
    "for i in range(8):\n",
    "    rt=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\") \n",
    "\n",
    "    for r in rt:\n",
    "        ratings.append(r.text)\n",
    "\n",
    "    \n",
    "        \n",
    "    rv=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "\n",
    "    for s in rv:\n",
    "        review.append(s.text)\n",
    "    \n",
    "    su=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "\n",
    "    for t in su:\n",
    "        summary.append(t.text)\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    nxt=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "    time.sleep(2)\n",
    "    nxt.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "time.sleep(3)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Iphone_review=pd.DataFrame({\"Ratings\":ratings[0:90],\"Review\":review[0:90],\"Review_Summary\":summary[0:90]})\n",
    "Iphone_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ebee6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KWIK FIT</td>\n",
       "      <td>Casual Trendy Sneaker Casual Shoes For Men Sne...</td>\n",
       "      <td>₹424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUNKASTON</td>\n",
       "      <td>Kwik FIT casual sneaker shoes and partywear sh...</td>\n",
       "      <td>₹158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KWIK FIT</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Canvas shoes for Men Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>mohliye</td>\n",
       "      <td>kardam&amp;sons casual sneaker shoes and luxury fa...</td>\n",
       "      <td>₹489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Zsyto</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>Stylish Comfortable Lightweight, Breathable Wa...</td>\n",
       "      <td>₹349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Skypy-31 Walking Shoes,Training Shoes,Sneakers...</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                                        Description   Price\n",
       "0    KWIK FIT  Casual Trendy Sneaker Casual Shoes For Men Sne...    ₹424\n",
       "1   DUNKASTON  Kwik FIT casual sneaker shoes and partywear sh...    ₹158\n",
       "2    URBANBOX                                   Sneakers For Men    ₹349\n",
       "3    KWIK FIT                                   Sneakers For Men    ₹362\n",
       "4        aadi              Canvas shoes for Men Sneakers For Men    ₹449\n",
       "..        ...                                                ...     ...\n",
       "95    mohliye  kardam&sons casual sneaker shoes and luxury fa...    ₹489\n",
       "96      Echor  Original Luxury Branded Fashionable Men's Casu...    ₹298\n",
       "97      Zsyto                                   Sneakers For Men  ₹1,049\n",
       "98      SPARX  Stylish Comfortable Lightweight, Breathable Wa...    ₹349\n",
       "99      BIRDE  Skypy-31 Walking Shoes,Training Shoes,Sneakers...    ₹549\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "'''\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/div/div/button\").click()\n",
    "search=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "search.send_keys('sneakers')\n",
    "SR=driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "SR.click()\n",
    "time.sleep(3)\n",
    "\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "price=[]\n",
    "\n",
    "\n",
    "pr=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "pr\n",
    "\n",
    "for i in pr:\n",
    "    \n",
    "    product_desc.append(i.text)   \n",
    "\n",
    "br=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "\n",
    "for i in br:\n",
    "    \n",
    "    brand.append(i.text)\n",
    "    \n",
    "rt=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "\n",
    "for i in rt:\n",
    "    \n",
    "    price.append(i.text)\n",
    "    \n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span\").click()\n",
    "time.sleep(3)\n",
    "\n",
    "pr=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "pr\n",
    "\n",
    "for i in pr:\n",
    "    \n",
    "    product_desc.append(i.text)   \n",
    "\n",
    "br=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "\n",
    "for i in br:\n",
    "    \n",
    "    brand.append(i.text)\n",
    "    \n",
    "rt=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "\n",
    "for i in rt:\n",
    "    \n",
    "    price.append(i.text)\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span\").click()\n",
    "time.sleep(3)\n",
    "\n",
    "pr=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "pr\n",
    "\n",
    "for i in pr:\n",
    "    \n",
    "    product_desc.append(i.text)   \n",
    "\n",
    "br=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "\n",
    "for i in br:\n",
    "    \n",
    "    brand.append(i.text)\n",
    "    \n",
    "rt=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "\n",
    "for i in rt:\n",
    "    \n",
    "    price.append(i.text)\n",
    "    \n",
    "Sneakers=pd.DataFrame({'Brand': brand[0:100],'Description':product_desc[0:100],'Price':price[0:100]})\n",
    "Sneakers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "19b7ede4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men KF 5 EP Basketball Shoes</td>\n",
       "      <td>8195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women React MR 3 Running Shoes</td>\n",
       "      <td>10495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>7649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one8 x PUMA</td>\n",
       "      <td>Men Fuse One8 Training Shoes</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Women Leather Heeled Boots</td>\n",
       "      <td>8799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Leather Stiletto Pumps with Laser Cuts</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Party Block Sandals</td>\n",
       "      <td>10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Textured Leather Loafers</td>\n",
       "      <td>9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Textured Leather Loafers</td>\n",
       "      <td>9490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand                             Description   Price\n",
       "0          Nike            Men KF 5 EP Basketball Shoes    8195\n",
       "1          ALDO               Men Leather Driving Shoes   12999\n",
       "2          Nike          Women React MR 3 Running Shoes   10495\n",
       "3      Skechers              Men Max Cushioning Running    7649\n",
       "4   one8 x PUMA            Men Fuse One8 Training Shoes    7999\n",
       "..          ...                                     ...     ...\n",
       "95      Bugatti              Women Leather Heeled Boots    8799\n",
       "96      Bugatti  Leather Stiletto Pumps with Laser Cuts    9999\n",
       "97      Saint G             Leather Party Block Sandals   10500\n",
       "98         Geox          Women Textured Leather Loafers    9990\n",
       "99         Geox          Women Textured Leather Loafers    9490\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image'''\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "driver.get('https://www.myntra.com/shoes')\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "Brand=[]\n",
    "des=[]\n",
    "price=[]\n",
    "\n",
    "br=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "\n",
    "for b in br:\n",
    "    Brand.append(b.text)\n",
    "\n",
    "de=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "\n",
    "for d in de:\n",
    "    des.append(d.text)\n",
    "    \n",
    "pr=driver.find_elements_by_xpath(\"//div[@class='product-price']/span[1]\")\n",
    "\n",
    "for p in pr:\n",
    "    price.append(p.text.split('Rs.')[1])\n",
    " \n",
    "time.sleep(3)\n",
    "\n",
    "nxt=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]/a\")\n",
    "time.sleep(3)\n",
    "nxt.click()\n",
    "time.sleep(3)\n",
    "\n",
    "br=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "\n",
    "for b in br:\n",
    "    Brand.append(b.text)\n",
    "\n",
    "de=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "\n",
    "for d in de:\n",
    "    des.append(d.text)\n",
    "    \n",
    "pr=driver.find_elements_by_xpath(\"//div[@class='product-price']/span[1]\")\n",
    "\n",
    "for p in pr:\n",
    "    price.append(p.text.split('Rs.')[1])    \n",
    "    \n",
    "Shoes=pd.DataFrame({\"Brand\":Brand[0:100],\"Description\":des[0:100],\"Price\":price[0:100]})\n",
    "Shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "3e90b142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td>48</td>\n",
       "      <td>83,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell New XPS 9305 Intel i7-1165G7 13.3 inches ...</td>\n",
       "      <td>62</td>\n",
       "      <td>1,26,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>2</td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...</td>\n",
       "      <td>38</td>\n",
       "      <td>86,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>3</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dell 15 (2021) i7-11370H Laptop, 16GB, 1TB SSD...</td>\n",
       "      <td>13</td>\n",
       "      <td>97,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...</td>\n",
       "      <td>11</td>\n",
       "      <td>96,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Refurbished) Dell 7480 Intel Core i7 14-Inch ...</td>\n",
       "      <td>2</td>\n",
       "      <td>46,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Infinix INBook X1 Pro Core i7 10th Gen - (16 G...</td>\n",
       "      <td>2</td>\n",
       "      <td>57,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Dell Latitude Laptop E7480 Intel Cor...</td>\n",
       "      <td>2</td>\n",
       "      <td>47,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating     Price\n",
       "0  Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...     48    83,990\n",
       "1  Dell New XPS 9305 Intel i7-1165G7 13.3 inches ...     62  1,26,900\n",
       "2  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...      2    57,990\n",
       "3  HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...     38    86,490\n",
       "4  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....      3    86,990\n",
       "5  Dell 15 (2021) i7-11370H Laptop, 16GB, 1TB SSD...     13    97,990\n",
       "6  ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...     11    96,990\n",
       "7  (Refurbished) Dell 7480 Intel Core i7 14-Inch ...      2    46,500\n",
       "8  Infinix INBook X1 Pro Core i7 10th Gen - (16 G...      2    57,999\n",
       "9  (Renewed) Dell Latitude Laptop E7480 Intel Cor...      2    47,990"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes'''\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "driver.get('https://www.amazon.in/')\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "search=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search.send_keys(\"Laptop\")\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div\").click()\n",
    "\n",
    "time.sleep(7)\n",
    "\n",
    "i7=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[4]/li[11]/span/a/span\")\n",
    "time.sleep(6)\n",
    "i7.click()\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "Title=[]\n",
    "Rating=[]\n",
    "Price=[]\n",
    "\n",
    "tl=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "\n",
    "for i in tl:\n",
    "    Title.append(i.text)\n",
    "time.sleep(3)   \n",
    "pr=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "    \n",
    "for i in pr:\n",
    "    Price.append(i.text)\n",
    "\n",
    "\n",
    "rt=driver.find_elements_by_xpath(\"//span[@class='a-size-base s-underline-text']\")\n",
    "for j in rt:\n",
    "    Rating.append(j.text)\n",
    "\n",
    "Laptop=pd.DataFrame({\"Title\":Title[0:10],\"Rating\":Rating[0:10],\"Price\":Price[0:10]})\n",
    "Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "2482dc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job_Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>deep learning, nlp, Natural Language Processin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>deep learning, python, machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist with SAS</td>\n",
       "      <td>Tech Mahindra Ltd</td>\n",
       "      <td>SAS, machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For Data Scientist + Python/R+ Predicti...</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>Predictive Modeling, R, python +4 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Urgent Requirement || Data Scientist || Noida</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>NLP, Artificial Intelligence, Natural Language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Immediate Joiners</td>\n",
       "      <td>Bristlecone India Limited</td>\n",
       "      <td>Data Scientist, Data Management, PhD +6 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Machine Learning (5-14 yrs)</td>\n",
       "      <td>Zyoin</td>\n",
       "      <td>Predictive Modeling, Data Science, SAS +7 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist- Fresher Opening - Newgen Softw...</td>\n",
       "      <td>Newgen Software Technologies Ltd.</td>\n",
       "      <td>python, nlp, Statistical Analyses +1 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Pitney Bowes India Pvt Ltd</td>\n",
       "      <td>Quest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst / Data Scientist</td>\n",
       "      <td>JK Technosoft Ltd</td>\n",
       "      <td>Data Visualization, Data Analysis, Machine Lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                          Machine Learning Engineer   \n",
       "1                                     Data Scientist   \n",
       "2                            Data Scientist with SAS   \n",
       "3  Hiring For Data Scientist + Python/R+ Predicti...   \n",
       "4      Urgent Requirement || Data Scientist || Noida   \n",
       "5                 Data Scientist - Immediate Joiners   \n",
       "6       Data Scientist - Machine Learning (5-14 yrs)   \n",
       "7  Data Scientist- Fresher Opening - Newgen Softw...   \n",
       "8                              Senior Data Scientist   \n",
       "9                      Data Analyst / Data Scientist   \n",
       "\n",
       "                             Company  \\\n",
       "0      GENPACT India Private Limited   \n",
       "1      GENPACT India Private Limited   \n",
       "2                  Tech Mahindra Ltd   \n",
       "3      GENPACT India Private Limited   \n",
       "4                   HCL Technologies   \n",
       "5          Bristlecone India Limited   \n",
       "6                              Zyoin   \n",
       "7  Newgen Software Technologies Ltd.   \n",
       "8         Pitney Bowes India Pvt Ltd   \n",
       "9                  JK Technosoft Ltd   \n",
       "\n",
       "                                         Job_Summary  \n",
       "0  deep learning, nlp, Natural Language Processin...  \n",
       "1            deep learning, python, machine learning  \n",
       "2                              SAS, machine learning  \n",
       "3             Predictive Modeling, R, python +4 more  \n",
       "4  NLP, Artificial Intelligence, Natural Language...  \n",
       "5       Data Scientist, Data Management, PhD +6 more  \n",
       "6     Predictive Modeling, Data Science, SAS +7 more  \n",
       "7          python, nlp, Statistical Analyses +1 more  \n",
       "8                                              Quest  \n",
       "9  Data Visualization, Data Analysis, Machine Lea...  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All the steps required during scraping should be done through code only and not manually\n",
    "'''\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[6]\").click()\n",
    "time.sleep(4)\n",
    "\n",
    "search=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")\n",
    "search.send_keys(\"Data Scientist\")\n",
    "driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button\").click()\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/i\").click()\n",
    "time.sleep(2)\n",
    "location=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "location.send_keys(\"noida\")\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\").click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "Job_Title=[]\n",
    "Company=[]\n",
    "Job_Summary=[]\n",
    "\n",
    "jt=driver.find_elements_by_xpath(\"//div[@class='info']/h2[1]\")\n",
    "for i in jt:\n",
    "    Job_Title.append(i.text)\n",
    "cm=driver.find_elements_by_xpath(\"//div[@class='company-info']/p\")\n",
    "for i in cm:\n",
    "    Company.append(i.text)\n",
    "Company2=Company[1:]\n",
    "\n",
    "js=driver.find_elements_by_xpath(\"//div[@class='job-basic-info show-flex']/div[4]\")\n",
    "for i in js:\n",
    "    Job_Summary.append(i.text)\n",
    "js=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[2]/div[2]/div/div[1]/div[7]/div[3]/div/div[3]/p\")\n",
    "Job_Summary.insert(-4,js.text)\n",
    "\n",
    "Ambition=pd.DataFrame({\"Job_Title\":Job_Title,\"Company\":Company2,\"Job_Summary\":Job_Summary})\n",
    "Ambition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "add2f1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary_records</th>\n",
       "      <th>Experience_Required</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Avg_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>3 yrs exp</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>₹ 29.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 32 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 5.6L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "      <td>₹ 18.9L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "      <td>2 yrs exp</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 27 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 81 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 46 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 14.8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 53 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Company        Salary_records Experience_Required  \\\n",
       "0                   Walmart  based on 11 salaries           3 yrs exp   \n",
       "1                  Ab Inbev  based on 32 salaries         3-4 yrs exp   \n",
       "2              Reliance Jio  based on 10 salaries           4 yrs exp   \n",
       "3                        ZS  based on 15 salaries           2 yrs exp   \n",
       "4                     Optum  based on 27 salaries         3-4 yrs exp   \n",
       "5         Fractal Analytics  based on 81 salaries         2-4 yrs exp   \n",
       "6           Tiger Analytics  based on 46 salaries         2-4 yrs exp   \n",
       "7              UnitedHealth  based on 53 salaries         2-4 yrs exp   \n",
       "8                   Verizon  based on 14 salaries           4 yrs exp   \n",
       "9  Ganit Business Solutions  based on 13 salaries           4 yrs exp   \n",
       "\n",
       "  Min_Salary Max_Salary Avg_Salary  \n",
       "0    ₹ 25.0L    ₹ 35.0L    ₹ 29.7L  \n",
       "1    ₹ 15.0L    ₹ 25.5L    ₹ 20.5L  \n",
       "2     ₹ 5.6L    ₹ 26.2L    ₹ 18.9L  \n",
       "3     ₹ 9.8L    ₹ 20.0L    ₹ 15.9L  \n",
       "4    ₹ 11.0L    ₹ 22.0L    ₹ 15.2L  \n",
       "5     ₹ 9.5L    ₹ 22.0L    ₹ 15.2L  \n",
       "6     ₹ 9.0L    ₹ 20.0L    ₹ 14.8L  \n",
       "7     ₹ 8.3L    ₹ 20.5L    ₹ 14.0L  \n",
       "8    ₹ 10.0L    ₹ 21.0L    ₹ 12.7L  \n",
       "9     ₹ 8.5L    ₹ 15.0L    ₹ 12.4L  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe.\n",
    "'''\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[4]\").click()\n",
    "time.sleep(4)\n",
    "search=driver.find_element_by_xpath(\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\")\n",
    "search.send_keys(\"Data Scientist\")\n",
    "time.sleep(1)\n",
    "driver.find_element_by_xpath(\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "com=[]\n",
    "slrd=[]\n",
    "exp=[]\n",
    "min1=[]\n",
    "max1=[]\n",
    "avg=[]\n",
    "\n",
    "c=driver.find_elements_by_xpath(\"//div[@class='name']/a\")\n",
    "for i in c:\n",
    "    com.append(i.text)\n",
    "    \n",
    "s=driver.find_elements_by_xpath(\"//div[@class='name']/span[1]\")\n",
    "for i in s:\n",
    "    slrd.append(i.text)\n",
    "    \n",
    "e=driver.find_elements_by_xpath(\"//div[@class='salaries sbold-list-header']\")\n",
    "for i in e:\n",
    "    exp.append(i.text.split('\\n')[-1])\n",
    "    \n",
    "m1=driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[1]\")\n",
    "for i in m1:\n",
    "    min1.append(i.text)\n",
    "    \n",
    "m2=driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[2]\")\n",
    "for i in m2:\n",
    "    max1.append(i.text)\n",
    "    \n",
    "a=driver.find_elements_by_xpath(\"//div[@class='average-indicator-wrapper']/p\")\n",
    "for i in a:\n",
    "    avg.append(i.text)\n",
    "    \n",
    "Job_Details=pd.DataFrame({\"Company\":com,\"Salary_records\":slrd,\"Experience_Required\":exp,\"Min_Salary\":min1,\"Max_Salary\":max1,\"Avg_Salary\":avg,})\n",
    "Job_Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18012bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
